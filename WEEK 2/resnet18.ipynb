{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPD3KMt/qvsnZtGgnoXy7yG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoPA607/SOC-2024/blob/main/WEEK%202/resnet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIda_a-hGQLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06bf8a60-5a03-439b-a43e-e90a4fd17eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 15 17:51:40 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ConvBlock\n",
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    super().__init__()\n",
        "    self.c=nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "    self.bn=nn.BatchNorm2d(out_channels)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.bn(self.c(x))\n",
        "\n",
        "#Bottleneck Residual Block\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels,out_channels, first=False):\n",
        "    super().__init__()\n",
        "    res_channels=out_channels//4\n",
        "    stride=1\n",
        "\n",
        "    self.projection=in_channels!=out_channels\n",
        "    if self.projection:\n",
        "      self.p=ConvBlock(in_channels, out_channels, 1, 2, 0)\n",
        "      stride=2\n",
        "      res_channels=in_channels // 2\n",
        "\n",
        "    if first:\n",
        "      self.p=ConvBlock(in_channels, out_channels, 1, 1, 0)\n",
        "      stride=1\n",
        "      res_channels=in_channels\n",
        "\n",
        "\n",
        "    self.c1=ConvBlock(in_channels, res_channels, 1, 1, 0)\n",
        "    self.c2=ConvBlock(res_channels, res_channels, 3, stride, 1)\n",
        "    self.c3=ConvBlock(res_channels, out_channels, 1, 1, 0)\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    f=self.relu(self.c1(x))\n",
        "    f=self.relu(self.c2(f))\n",
        "    f=self.c3(f)\n",
        "\n",
        "    if self.projection:\n",
        "      x=self.p(x)\n",
        "\n",
        "    h=self.relu(torch.add(f , x))\n",
        "\n",
        "    return h\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLB2JLWbPg7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, no_blocks, in_channels=3,classes=1000):\n",
        "    super().__init__()\n",
        "    out_features=[256, 512, 1024, 2048]\n",
        "    self.blocks=nn.ModuleList([ResidualBlock(64,256, True)])\n",
        "\n",
        "    for i in range(len(out_features)):\n",
        "      if i>0:\n",
        "         self.blocks.append(ResidualBlock(out_features[i-1], out_features[i]))\n",
        "      for _ in range(no_blocks[i]-1):\n",
        "         self.blocks.append(ResidualBlock(out_features[i], out_features[i]))\n",
        "\n",
        "\n",
        "    self.convl=ConvBlock(in_channels,64 , 72,2,3)\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc=nn.Linear(2048, classes)\n",
        "\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.relu(self.convl(x))\n",
        "    x=self.maxpool(x)\n",
        "    for block in self.blocks:\n",
        "      x=block(x)\n",
        "    x=self.avgpool(x)\n",
        "    x=torch.flatten(x,1)\n",
        "    x=self.fc(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UV-GgvGoUB2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#no_blocks=[3, 4, 6, 3]\n",
        "#res=ResNet(no_blocks)\n",
        "#res(torch.rand(1,3,224,224)).shape"
      ],
      "metadata": {
        "id": "Q78gjUVQXC1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "\n",
        "test_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((120, 120)),\n",
        "    torchvision.transforms.CenterCrop((110, 110)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize((120, 120)),\n",
        "    torchvision.transforms.RandomCrop((110, 110)),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "valid_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=test_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=256, shuffle=False)\n",
        "for images, labels in train_loader:\n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    print('Class labels of 10 examples:', labels[:10])\n",
        "    break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D07pn1lZJ27W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d15d0b9-b6a1-48c8-9a66-df8d95168813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 48677849.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Image batch dimensions: torch.Size([256, 3, 110, 110])\n",
            "Image label dimensions: torch.Size([256])\n",
            "Class labels of 10 examples: tensor([5, 5, 6, 8, 2, 9, 9, 7, 9, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResNet(no_blocks=[3, 4, 6, 3]).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(20):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print training progress\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
        "                epoch + 1, 20, i + 1, len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Test Accuracy: {}%'.format((correct / total) * 100))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnllabHjF8yk",
        "outputId": "3abbaf46-a459-4deb-cb64-391fdf9d3aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Step [100/196], Loss: 1.8396\n",
            "Epoch [2/20], Step [100/196], Loss: 1.4568\n",
            "Epoch [3/20], Step [100/196], Loss: 1.4478\n",
            "Epoch [4/20], Step [100/196], Loss: 1.3708\n",
            "Epoch [5/20], Step [100/196], Loss: 1.1978\n",
            "Epoch [6/20], Step [100/196], Loss: 1.1527\n",
            "Epoch [7/20], Step [100/196], Loss: 1.2049\n",
            "Epoch [8/20], Step [100/196], Loss: 0.9893\n",
            "Epoch [9/20], Step [100/196], Loss: 1.3488\n",
            "Epoch [10/20], Step [100/196], Loss: 0.9615\n",
            "Epoch [11/20], Step [100/196], Loss: 1.0267\n",
            "Epoch [12/20], Step [100/196], Loss: 0.9656\n",
            "Epoch [13/20], Step [100/196], Loss: 1.1986\n",
            "Epoch [14/20], Step [100/196], Loss: 1.0551\n",
            "Epoch [15/20], Step [100/196], Loss: 0.8573\n",
            "Epoch [16/20], Step [100/196], Loss: 0.8657\n",
            "Epoch [17/20], Step [100/196], Loss: 0.7054\n",
            "Epoch [18/20], Step [100/196], Loss: 0.8071\n",
            "Epoch [19/20], Step [100/196], Loss: 1.0044\n",
            "Epoch [20/20], Step [100/196], Loss: 0.7744\n",
            "Test Accuracy: 61.39%\n"
          ]
        }
      ]
    }
  ]
}